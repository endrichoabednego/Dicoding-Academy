# -*- coding: utf-8 -*-
"""terapan2fix.ipynb

Automatically generated by Colaboratory.

Original file is located at
    https://colab.research.google.com/drive/1CJeIutBtJFjZoE7scrEDT60z1CnpNW92

Submission Proyek Akhir : Membuat Model Sistem Rekomendasi

---


Modul : Machine Learning Terapan

---


Nama / ID Dicoding : Endricho Abednego / M239X0468

## Import Library
Melakukan import library yang berguna untuk memanggil fungsi-fungsi yang diperlukan untuk algoritma model
"""

import numpy as np
import pandas as pd
import matplotlib.pyplot as plt
import warnings
warnings.filterwarnings('ignore')
import ast
import nltk 
from nltk.stem import PorterStemmer,WordNetLemmatizer
from sklearn.feature_extraction.text import CountVectorizer, TfidfVectorizer
import matplotlib.pyplot as plt
from sklearn.metrics.pairwise import cosine_similarity

! pip install kaggle
! mkdir ~/.kaggle 
! cp kaggle.json ~/.kaggle/
! chmod 600 ~/.kaggle/kaggle.json

"""##Zip Extraction 
Dataset di yang telah di install masih berupa zip, sehingga diperlukan zip extraction supaya dapat dibaca oleh sistem.
"""

! kaggle datasets download gazu468/tmdb-10000-movies-dataset

! unzip tmdb-10000-movies-dataset.zip

"""## Load Dataset
Setelah dataset telah di unzip dan terekstrasi maka dataset perlu di load ke dalam memori dengan pembacaan file. 
"""

film = pd.read_csv("/content/10000 Movies Data")
dataFilm = pd.read_csv("/content/10000 Movies Data")
kredit = pd .read_csv("/content/10000 Credits Data")

kredit.drop("title",axis=1, inplace=True)

"""##File Merge Dataset
Perlu dilakukan merge dataset untuk pengolahan data karena pada dataset ini terdaat 2 files yaitu 10000 Movies Data dan 10000 Credits Data dengan menggunakan fungsi merge()
"""

film=film.merge(kredit, on="Movie_id")

film.head(5)

film=film[['Movie_id','title','Genres',"Keywords",'overview','Cast','Crew']]

film.isnull().sum()

"""#Menghilangakan data yang bernilai Null"""

film.dropna(inplace=True)
film.duplicated().sum()

"""#Melakukan convert string menjadi list"""

ast.literal_eval

def convertString1(obj):
    L =[]
    for i in ast.literal_eval(obj):
        L.append(i['name'])
    return L

film['Genres'] = film['Genres'].apply(convertString1)
film.head()

film['Keywords']=film['Keywords'].apply(convertString1)

def convertString2(obj):
    L =[]
    counter=0
    for i in ast.literal_eval(obj):
        if counter !=3:
            L.append(i['name'])
            counter+=1
    return L

film['Cast']=film['Cast'].apply(convertString2)

def fetch(obj):
    L =[]
    for i in ast.literal_eval(obj):
        if i['job']=="Director":
            L.append(i['name'])
            break
    return L

film['Crew']=film['Crew'].apply(fetch)

film['overview']=film['overview'].apply(lambda x: x.split())

film['Genres']=film['Genres'].apply(lambda x : [i.replace(" ","")for i in x])
film['Keywords']=film['Keywords'].apply(lambda x : [i.replace(" ","")for i in x])
film['Cast']=film['Cast'].apply(lambda x : [i.replace(" ","")for i in x])
film['Crew']=film['Crew'].apply(lambda x : [i.replace(" ","")for i in x])

"""Penambahan kolom 'tags' dalam dataset yang berisi gabungan dari kolom *'Genres','Keywords','Cast','Crew','overview'* untuk proses penghitungan kata dalam algoritma *Bag of Words*"""

film['tags']= film['Genres'] + film['Keywords'] + film['Cast'] + film['Crew'] + film['overview']

film.head(5)

df = film[['Movie_id','title','tags']]

df['tags']=df['tags'].apply(lambda x: " ".join(x))
df['tags']=df['tags'].apply(lambda x: x.lower())

"""# Visualisasi Data
Grafik berikut menunjukan 15 film terpopuler yang ada dalam dataset
"""

pop= dataFilm.sort_values('popularity', ascending=False)
plt.figure(figsize=(15,4))

plt.barh(pop['title'].head(15),pop['popularity'].head(15), align='center', color='blue')
plt.gca().invert_yaxis()
plt.xlabel("Popularity")
plt.title("Film Terpopuler")

"""##Modeling
Proses pembuatan sistem rekomendasi menggunakan metode pendekatan content based filtering. Pada model ini, akan digunakan TF-IDF Vectorizer. Teknik tersebut berfungsi untuk menemukan fitur penting dari setiap kategori penting.

#Stemming
Melakukan penghapusan beberapa akhir karakter dalam sebuah kata.
"""

nltk.download('wordnet')
ps = PorterStemmer()

def stemming(text):
    y=[]
    for i in text.split():
        y.append (ps.stem(i))
    return " ".join(y)

#lemmitization
df['tags1']=df['tags'].apply(stemming)
#porter_steammer
df['tags']=df['tags'].apply(stemming)

"""Melakukan CounterVectorizer dengan porterSteamer"""

countVect= CountVectorizer(max_features=8000, stop_words="english")
vector=countVect.fit_transform(df['tags']).toarray()
#cek nama fitur random
countVect.get_feature_names()[1200]

"""melakukan proses TFIDF menggunakan lemmitization"""

tfVect=TfidfVectorizer(max_features=7000,analyzer='word',stop_words="english")
tfdf_features=tfVect.fit_transform(df['tags1'])
tfVect.get_feature_names_out()[1322]

"""Proses transformasi data untuk mengubah data ke dalam bentuk matriks"""

dataFilm['overview'] = dataFilm['overview'].fillna('')
tfidf_matrix = tfVect.fit_transform(dataFilm['overview'])
tfidf_matrix.shape

"""Kemudian untuk menghasilkan vektor tf-idf dalam bentuk matriks kita akan memanggil fungsi todense()"""

tfidf_matrix.todense()

tfidf_matrix

"""#Cosine Similarity
Pada tahap ini, akan dipanggil fungsi cosine_similarity() yang berfungsi untuk menghitung derajat kesamaan.
"""

cosine_sim = cosine_similarity(tfidf_matrix) 
cosine_sim

similarity = cosine_similarity(vector)

df[df['title']=='Avatar'].index[0]

indices = pd.Series(dataFilm.index, index=dataFilm['title']).drop_duplicates()

cosine_sim_df = pd.DataFrame(cosine_sim, index=dataFilm['title'], columns=dataFilm['title'])
print('Shape:', cosine_sim_df.shape)

"""Algoritma model dengan Bag of Words"""

def reccomendBoW(movie):
    movie_index=df[df['title']==movie].index[0]
    distance=similarity[movie_index]
    movies_list=sorted(list(enumerate(distance)), reverse=True, key=lambda x : x[1])[1:17]
    
    for i in movies_list:
        print(df.iloc[i[0]].title)

reccomendBoW('Batman Begins')

"""Algroitma model dengan Content Based Filtering 

"""

def reccomendCBF(movie, similarity_data=cosine_sim_df, items=dataFilm[['title',]], k=15):

    index = similarity_data.loc[:,movie].to_numpy().argpartition(range(-1, -k, -1))

    closest = similarity_data.columns[index[-1:-(k+2):-1]]
    
    closest = closest.drop(movie, errors='ignore')
 
    return pd.DataFrame(closest).merge(items)

reccomendCBF('Batman Begins')

